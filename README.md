# Jax Bandits

Jax based library for multi-armed bandit problems

Includes
- UCB1, UCB2
- Thompson Sampling
- epsilon-greedy


## Usage



```python





```